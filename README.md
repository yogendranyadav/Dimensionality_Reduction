# Dimensionality Reduction Techniques

Worked on this exersice to better understand the Dimensionality Techniques like PCA (Principal Component Analysis), LDA ( Linear Discriminant Analysis) and TSNE ( T-Distributed Stochastic Neighbour Embedding).

## Article:
  I followed the below article to recreate the work. This helped to better understanding of these concepts.
 -  [Intro to Dimensionality Reduction](https://www.kaggle.com/arthurtok/interactive-intro-to-dimensionality-reduction)
 
## Introduction:

   There already exists a plethora of notebooks discussing the merits of dimensionality reduction methods, in particular the Big 3 of PCA (Principal Component Analysis), LDA ( Linear Discriminant Analysis) and TSNE ( T-Distributed Stochastic Neighbour Embedding). Quite a handful of these have compared one to the other but few have gathered all 3 in one go. Therefore this notebook will aim to provide an introductory exposition on these 3 methods as well as to portray their visualisations interactively and hopefully more intuitively via the Plotly visualisation library. The chapters are structuredas follows:

- **Principal Component Analysis ( PCA )** - Unsupervised, linear method
- **Linear Discriminant Analysis (LDA)** - Supervised, linear method
- **t-distributed Stochastic Neighbour Embedding (t-SNE)** - Nonlinear, probabilistic method
Lets go.
 
## Dataset Used:
  
- [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer/data)
